<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>PseudoChat Dataset Collection</title>
    <link rel="stylesheet" href="/static/styles.css" />
</head>

<body>
    <header>
        <h1>PseudoChat Dataset Collection</h1>
        <div class="sidebar">
            <a href="/">
                <img src="/static/images/PseudoLabLogo.png" alt="PseudoLab Logo">
            </a>
            <button onclick="openIntroduction()">Introduction</button>
            <button onclick="openInitialTask()">Initial Task</button>
            <button onclick="openMakePrompt()">Make Prompt</button>
            <button onclick="openMakeCompletion()">Make Completion</button>
            <button onclick="openDashboard()">Dashboard</button>
        </div>
    </header>

    <main>
        <h2>Wellcome to PseudoChat Instruction Dataset Building Project!</h2>
        <ul>
            <li>본 프로젝트의 목적은 구축에 누구나 참여할 수 있으며, 공개적으로 사용 가능한 한국어 Instruction 데이터셋을 구축하는 것입니다.</li>
        </ul>
        <h2>데이터셋 제작 의도</h2>
        <ul>
            <li><strong>Human Instruction과 Feedback이 반영된 데이터셋</strong>은 사전 학습된 언어 모델을 학습시켜 인간과 유사한 Text Instruction을 생성하는 데 유용한 리소스입니다.</li>
            <li>언어 모델을 단순히 거대하게만 만드는 것은 여러 태스크의 성능을 높이기는 하나, 이를 사용하는 유저들의 질문 의도를 파악하는데 효과적이지 않습니다. </li>
            <li>또한, <strong>사실성이 떨어지고 유해하며, 유저에게 도움이 되지 않는 답변</strong>을 생성하는 경향이 있습니다.</li>
            <li>이에 <strong>OpenAI의 InstructGPT</strong>는 인간의 피드백을 이용하여 유저의 질문 의도를 따르는 <strong>Aligning Language Model 방법론</strong>을 사용하여 이러한 문제를 해결하고 보다 유용한 답변을 출력하도록 합니다.</li>
            <li>하지만 InstructGPT 방법론을 사용한 ChatGPT의 경우 학습에 사용한 데이터 570GB 중 한국어 데이터 비중이 <strong>1.3%에 불과</strong>하며, <strong>공개되어 있지 않습니다.</strong></li>
            <li>따라서 가짜연구소에서는 <strong>한국어로 이루어지고 구축에 누구나 참여할 수 있으며 공개적으로 사용할 수 있는 Instruction 데이터셋과 Human Feedback 데이터셋을 구축하고자 합니다.</strong></li>
        </ul>
        <h2>데이터셋 제작 목표</h2>
        <ul>
            <li>공개된 LLMs 모델을 사용하여 InstructGPT에 사용된 데이터셋과 유사한 Human Feedback이 적용된 데이터셋을 구축하는 것입니다.</li>
            <li>모델의 방법론을 학습하고 이를 구현하는 것도 좋지만, 본 데모에서는 Prompt-Instruction 데이터셋 구축이 목표입니다.</li>
            <li><strong>하지만</strong>, 추후 모델을 통한 응답에 대해 평가하거나 수정하는 작업을 추가할 계획입니다.</li>
        </ul>
        <h2>PseudoLab</h2>
        <ul>
            <li>가짜연구소는 머신러닝/데이터사이언스를 중심으로 모인 비영리 커뮤니티입니다.</li>
            <li>성장의 앙상블이 만들어내는 울림을 통해 개인과 커뮤니티의 성장의 사이클을 함께 만들어나가요!</li>
            <li><strong><a href="https://pseudo-lab.com/">PseudoLab</strong></li>
        </ul>
        <h2>Contributors</h2>
        <ul>
            <li><a href="https://www.linkedin.com/in/video-jeong/">정영상</a></li>
            <li><a href="https://www.linkedin.com/in/neulvo/">염성현</a></li>
            <li><a href="https://www.linkedin.com/in/sangwon-baek-74a3241b7/">백상원</a></li>
        </ul>
    </main>
    
    <footer>
        <p>Thank you for contributing to PseudoChat training data!</p>
    </footer>

    <script defer src="/static/scripts.js"></script>
</body>

</html> 
