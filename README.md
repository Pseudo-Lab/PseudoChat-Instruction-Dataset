# PseudoChat-Instruction-Dataset

## Introduce

본 프로젝트의 목적은 누구나 참여할 수 있는 공개적으로 사용 가능한 한국어 Instruction 데이터셋 구축입니다.

## Tryout site

[🔥 PseudoChat Assistant]()

# 데이터셋 제작 의도

## 데이터셋의 중요성

- 데이터셋 중 **Human Instruction과 Feedback이 반영된 부분은 사전 학습된 언어 모델로 하여금 인간이 작성한 것과 유사한 **Text Instruction을 생성하게 만드는데 있어 중요한 자원**입니다.
- 그러나 단순히 언어 모델의 크기를 키우는 것은 다양한 Task에서의 성능 향상에 도움이 될지는 몰라도, 사용자의 질문 의도를 정확히 파악하고 그에 맞는 답변을 생성하는 데에는 크게 효과적이지 않습니다
- 더욱이, 이런 방식은 **사실적이지 않거나 유해하며 사용자에게 도움이 되지 않는 응답을 생성하는 경향**이 있습니다.
- 그런 문제를 해결하기 위해, OpenAI는 인간의 피드백을 활용한 **Aligning Language Model 방법론**을 도입하였고, 이를 통해 ChatGPT의 토대가 되는 **InstructGPT**를 개발했습니다. 
- 이 방법론은 **사용자의 질문 의도를 정확히 이해**하고, **더욱 유익한 응답을 생성하는 데 중점**을 두고 있습니다.

## 한국어 데이터셋의 부재

- **OpenAI**의 **ChatGPT**의 기반이 되는 GPT-3를 학습할 때 사용된 7,000억개의 학습 토큰 중 한국어 데이터 비중은 **0.01697%에 불과**하며, **데이터 조차 공개되어 있지 않습니다.**
- **MS**의 **LLaMA**는 웹상에 공개된 데이터만을 사용했으며, 학습데이0터는 20개 언어로 구성되었으나 **한국어는 존재하지 않습니다.**
- 또한 현존하는 오픈소스 Instruction 한국어 데이터셋은 번역 API를 통해 번역하거나 GPT 모델을 통한 생성 데이터가 주를 이루고 있습니다.
- 이런 문제를 해결하고자 가짜연구소는 한국어로 구성된, **누구나 제작에 참여 가능하고 공개적으로 사용할 수 있는 Instruction 데이터셋과 Human Feedback 데이터셋을 구축하려 합니다.**

# **데이터셋 제작 목표**

- 우리의 목표는 **공개된 LLMs 모델을 활용하여 InstructGPT에서 사용된 것과 유사한 Human Feedback이 적용된 데이터셋을 구축**하는 것입니다.
- 모델의 방법론을 학습하고 적용하는 것도 중요하지만, **핵심 목표**는 **Prompt-Instruction 데이터셋의 구축**입니다.
- 뿐만 아니라, **추후 모델을 통해 생성된 응답을 평가하거나 Human-made 데이터셋을 평가하고 수정하는 작업 등을 포함할 예정입니다.**

## About PsuedoLab
- 가짜연구소는 머신러닝/데이터사이언스를 중심으로 모인 비영리 커뮤니티입니다.
- 성장의 앙상블이 만들어내는 울림을 통해 개인과 커뮤니티의 성장의 사이클을 함께 만들어나가요!
- [PseudoLab 찾아가기](https://pseudo-lab.com/)

## Authors
프로젝트에 참여한 가짜연구소 6기 멤버 명단입니다.
- [정영상](https://www.linkedin.com/in/video-jeong/)
- [염성현](https://www.linkedin.com/in/neulvo/)
- [백상원](https://www.linkedin.com/in/sangwon-baek-74a3241b7/)
